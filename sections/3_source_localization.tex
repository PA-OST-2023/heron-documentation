\graphicspath{ {images/3_source_localization/} }
\chapter{Sound Source Localization}
\section{Physical background}
This section shows some underling fundamentals on which the following described theory is based on.
\todo{Schribe}

\section{Sound Source Localization Methods}
\acrfull{ssl} is a well researched area with many applications.
\cite{nat_skript}
The basic system can be brought into two categories, time based or power based methods.
\subsection{Power based SSL}
The idea of power based SSL is based of the known propagation properties of sound waves in air.
BlaBlaBla \todo{short text}
However for this method to work some properties of the sound source have to be known.
Additionally the sensors that measure the sound power levels have to be calibrated \dots

\subsection{Time Based SSL}
Another group of \acrshort*{ssl} is based on the time when the
signal is received by the microphones.
Given a source at a location $\bm{S} = (x_S,y_S)^T$ and $N$ microphones at locations
$\bm{M_n} = (x_n,y_n)^T$ the time it takes for a acoustic signal from the source to reach a microphone is
\begin{equation}
	t_n = \frac{\lVert \bm{S} - \bm{M_n}\rVert}{c}
	= \frac{\sqrt{\left(x_S - x_n\right) + \left(y_S - y_n\right)}}{c} .
\end{equation}
So if $t_n$ is known for a microphone, the location of the source can be limited to point on a circle
around $M_n$ with a radius of $t_n c$.
Given three or more microphones the intersection of these circles will show th location of the source.
However in many cases this approach is not realistic since $t_n$ is generally not know.
It would require some sort of a synchronization between the microphones and the sources.
\subsubsection{Near-Field}
The next time property that could be used is the \acrfull{tdoa} which between
two microphones $\bm{M_n}$ and $\bm{M_m}$ is defined as
\begin{equation}
	t_{n, m} = t_m - t_n = \frac{\lVert \bm{S} - \bm{M_m}\rVert - \lVert \bm{S} - \bm{M_n}\rVert}{c}.
\end{equation}
With this equation $\bm{S}$ can be interpreted as the set of points that lie on a hyperbola
which fixed points are the Microphones and the vertices are $c t_{n,m}$m apart.
To find the location of $\bm{S}$ a minimum of four microphones is now needed.
This approach works only if we can assume that the curvature of the incoming sound waves
at the microphones is big enough. Figure \ref{ssl:fig:near field} shows such a arrangement
which is generally known as the near-field scenario.
It is generally said, that the near-field assumption holds when the distance from the source
to the array isn't much greater than the size of the array.
In Figure \ref{ssl:fig:hyperbola} it can be seen how the resulting hyperbolas from the
\acrshort{tdoa} intersect at the point $\bm{S}$.


\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{NearField.pdf}
		\caption{Acoustic model used for the near field \acrshort{ssl}.}
		\label{ssl:fig:near field}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{hyperbola.pdf}
		\caption{A selection of the hyperbolas resulting from the time-delays $t_{m,n}$.}
		\label{ssl:fig:hyperbola}
	\end{subfigure}
	\caption{Near field \acrshort{ssl} with a linear microphone Array.
		Since the microphones are distributed on a straight line a degree of freedom is lost and
		$\bm{S}$ mirrored at this line is also a possible solution.}
	\label{fig:three graphs}
\end{figure}

\subsubsection{Far-Field}
When the source is much further away than the size of the Array, as depicted
in Figure \ref{ssl:fig:far field}, the curvature of the sound wave at the array is negligible.
This is generally known as the far-field case.
Now the sound waves aren't modeled as spherical waves but rather as planar waves.
Given such a planar wave only the direction in which the source is placed can be determined with the TDOAs.

% Beamforming_general_S1110865703212038

\begin{figure}
	\centering
	%    \includegraphics[width=0.25\textwidth]{mesh}
	\includegraphics[]{FarField.pdf}
	\caption{Far-Field case. The Curvature of the sound-waves from S at the array
		is almost zero.}
	\label{ssl:fig:far field}
\end{figure}

\todo{Decission why this}
In this thesis the focus is set on the far-field case, due
\todo{literature}

\subsection{Direction of arrival estimation}
Lots of research has been made on how to estimate the \acrfull*{doa} of a source
with appropriate sensors.

\todo{brief lierature study}

In this thesis the focus was set on far-field techniques considering that the
goal is to detect drones which are usually several meters above ground.
%Constructing a microphone array 

\subsection{Beamforming}
Beamforming is a popular method for estimating the \acrshort{doa} of a signal.

To better show the fundamental principles of beamforming an example is used
where the goal isn't to estimate a \acrshort{doa} but to send a signal
in a desired direction using microphones.
Figure ref{ssl:fig:beamforming1} shows such a case in $\mathbb{R}^2$
where a linear array of N sound sources beam a sine wave $x(t) = \sin(\omega t)$ 
in the direction of $\varphi$.
This is achieved by adding a phase shift to the sine wave
at each microphone resulting in $x_n(t) = sin(\omega t + \alpha_n)$.
When the phase shifts are properly selected the points where the waves positively
interfere form a beam.
Given this example with a narrow band signal, the signal at each source
can be written as
\begin{equation}
	x_n(t) = \Re(sin(\omega t) e^{j\omega \alpha_n})
\end{equation}
and more generalized as 
\begin{equation}
  \label{ssl:eq:beamSteerOut}
  X(t, \varphi) = 
  \Re\left(
    sin(\omega t)
    \underbrace{
      \begin{pmatrix} 
        e^{-j\alpha_0(\omega, \varphi)} \\ 
        e^{-j\alpha_1(\omega, \varphi)} \\
        \vdots \\ 
        e^{-j\alpha_{N-1}(\omega, \varphi)} 
      \end{pmatrix}}_{W(\varphi, \omega)}
  \right).
\end{equation}
The vector $W(\varphi, \omega)$ is commonly known as the steering vector.
It can be seen that the steering vector is dependent on $\omega$ and 
will therefore only have the desired effect on signals with frequencies 
close to $\omega$.
How to use beamforming with wider band signals will be shown later in this chapter.
\begin{figure}
	\centering
	%    \includegraphics[width=0.25\textwidth]{mesh}
	\includegraphics[]{beamforming_1.pdf}
	\caption{Phase differences between the array elements create positive interference at the red lines.
		The gray circles correspond the waves' local maxima}
	\label{ssl:fig:beamforming1}
\end{figure}

If the goal is to estimate the direction of a sound signal with microphones 
$x_n(t)$ is now defined as the signal measured by the nth microphone.
Now \eqref{ssl:eq:beamSteerOut} is rewritten to 
\begin{equation}
  \label{ssl:eq:beamSteerIn}
  Y(t, \varphi) = 
    \underbrace{
      \begin{pmatrix} 
        x_0(t) \\ 
        x_1(t) \\
        \vdots \\ 
        x_{N-1}(t)
    \end{pmatrix}}_{X(t)}
    \odot
    \underbrace{
      \begin{pmatrix} 
        e^{-j\alpha_0(\omega, \varphi)} \\ 
        e^{-j\alpha_1(\omega, \varphi)} \\
        \vdots \\ 
        e^{-j\alpha_{N-1}(\omega, \varphi)} 
      \end{pmatrix}}_{W(\varphi, \omega)}
\end{equation}
where depending on the method used either $Y(t, \varphi)$ is further processed, or the 
method directly uses $X(t)$ for the \acrshort*{doa} estimation.

\subsubsection{Steering Vector}
The calculation of the Steering Vector is dependent on different factors.
The two main factor can be broken down to the geometry of the microphone array
and the direction in which the source lies. 
Again the formulas are derived for a circular array in $\mathbb{R}^2$ and are then expanded into $\mathbb{R}^3$.
A circular array where all the microphones are 
placed on a circle is convenient for the use of polar coordinates and the 
formulas can also be used for any other array described in polar coordinates.

Figure \ref*{ssl:fig:steering} shows such an array with five equally spaced microphones $M_n$.
The goal of the steering vector is to delay the measured signal at each microphone so that
they each have the same phase and therefore positively interfere.
To calculate these delays a reference point must firstly be defined, here it is the center of the circle.
Because a far-field model is used the sound pressure level is equal along lines perpendicular
to its propagation direction.
With the magenta line as the reference line, each measured signal from the microphones must be
phase shifted with 
\begin{equation}
  \alpha_n = 
  \frac{
    \lVert\bm{d}_n(\varphi_s)\rVert \omega}
    {c} 
    \hat{\bm{d}}_n(\varphi_s) \cdot \hat{\bm{d}}_s.
\end{equation}
The Term $\hat{\bm{d}}_n(\varphi_s) \cdot \hat{\bm{d}}_s$ is needed to determine
if a phase shift is positive or negative.
Using the trigonometric properties of a right triangle
\begin{equation}
  \lVert\bm{d}_n(\varphi_s)\rVert \hat{\bm{d}}_n(\varphi_s) \cdot \hat{\bm{d}}_s = r_{m_n} \cos(\varphi_s - \varphi_{m_n})
\end{equation}
and therefore
\begin{equation}
  \alpha_n = 
  r_{m_n} \cos(\varphi_s - \varphi_{m_n})
  \frac{\omega}{c}.
  \label{ssl:eq:beamr2}
\end{equation}
This formula can be used for any microphone with polar coordinates
$(\varphi_{m_n}, r_{m_n})$ and can therefore be used for any array configuration
described in polar coordinates.
\begin{figure}
  \centering
  %    \includegraphics[width=0.25\textwidth]{mesh}
  \includegraphics[]{steering_vector.pdf}
  \caption{BalaBula}
  \label{ssl:fig:steering}
\end{figure}

To expand this idea into $\mathbb{R}^3$ the spherical coordinate system is now used.
This adds the angle $\theta$ as the inclination.
When $\theta = \pi/2$ it is the same situation that has already been looked at.
But as $\theta$ aproaches 0 the speed of the wavefront projectet onto the
surface of the array increases. 
This adds a term to \eqref{ssl:eq:beamr2}
\begin{equation}
	\alpha_n = 
	r_{m_n} \cos(\varphi_s - \varphi_{m_n})
	\frac{\omega \sin(\theta)}{c}.
  \label{ssl:eq:beamr3}
\end{equation}

\subsubsection{Delay and Sum Beamformer}
The basic beamformer is the delay and sum Beamformer
\begin{equation}
	\label{ssl:eq:delAndSum}
	y(t, \varphi, \theta) = 
	  \underbrace{
		\begin{pmatrix} 
		  x_0(t) \\ 
		  x_1(t) \\
		  \vdots \\ 
		  x_{N-1}(t)
	  \end{pmatrix}}_{X(t)}
	  \cdot
	  \underbrace{
		\begin{pmatrix} 
			e^{-j\alpha_0(\omega, \varphi, \theta)} \\ 
			e^{-j\alpha_1(\omega, \varphi, \theta)} \\
			\vdots \\ 
			e^{-j\alpha_{N-1}(\omega, \varphi, \theta)} 
		\end{pmatrix}}_{W(\varphi, \theta, \omega)}.
\end{equation}
Notice how intead of the Hadamard product, the scalar product is now used.
$y(t, \varphi, \theta)$ is therefor the sum of the delayed signals.
If the angles of the steering vector point towards a source its 
signal will be amplified.
By using the delays calculated for the steering vector $X(t)$ can
be calculated to simulate a source in a specifig direction
\begin{equation}
	X(t, \varphi_s, \theta_s) = 
	e^{j\omega t}
	\begin{pmatrix} 
		e^{j\alpha_0(\omega, \varphi_s, \theta_s)} \\ 
		e^{j\alpha_1(\omega, \varphi_s, \theta_s)} \\
		\vdots \\ 
		e^{j\alpha_{N-1}(\omega, \varphi_s, \theta_s)} 
	\end{pmatrix}
\end{equation}
The amplitude response of an array using delay and sum beamforming can
now be calculated with
\begin{equation}
	G(\phi, \theta, \omega) = 
	\frac{
		\lvert X(0, \phi_s, \theta_s) \cdot W(\phi, \theta) \rvert}
	{
		N
	}.
\end{equation}
In Figure \ref*{ssl:fig:CircBmResponse} two such repsonses with different 
frequencies can be seen.


\begin{figure}[h]
	\centering
	\begin{subfigure}[t]{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{radial_1200_circ.pdf}
		\caption{\(G(\phi, \theta, \omega)\) with $\theta = \pi/2$ for three different frequencies}
		\label{ssl:fig:CircBmPhi}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.45\textwidth}
		\centering
		\includegraphics[width=\textwidth]{radial_1200_circ_theta.pdf}
		\caption{\(G(\phi, \theta, \omega)\) with $\phi = 0$ for three different frequencies. 
		$(\phi= 0, \theta = -45^\circ)$ is the same as $(\phi= 180^\circ, \theta = 45^\circ)$.
		The mirror along the horizontal axis comes from the flat geometry of the array which makes
		it impossible to distinguish if a sound comes from $\theta$ or $180 + \theta$.} 
		\label{ssl:fig:CircBmTheta}
	\end{subfigure}
	\caption{Delay and Sum Beamformer response for a circular array with $N=16$ microphones 
	and a radius $r = 0.25$m. }
	\label{ssl:fig:CircBmResponse}
\end{figure}

\newpage
\section{Simulator}
In order to experiment with different microphone arrangements and algorithms a simulator was developed.
Since the simulator wasn't the main focus of this Thesis, its functionality was kept simple.
The simulator lets you place acoustic sources and microphones in a $\mathbb{R}^3$ space and calculates
the measured signals at each microphone.

\subsection{Simulation Model}
For sake of simplicity the sources were modeled as omnidirectional point-sources and the
microphones are omnidirectional as well.
The Sound Pressure Level of a source is defined at one meter distance from their position and decreases
squarely with the distance.
The perceived sound at any point $P$ can now be described as
\begin{equation}
	\label[type]{ssl:eq:simcont}
	y(P, t) = \sum_{I} \frac{x_i(t - \lVert P - S_i\rVert/c)}{\lVert P - S_i\rVert}.
\end{equation}
Where $S_i$ is the position of the nth Source and $x_i(t)$ is its output sound.
Since the simulation is done numerically and with pre recorded audio files with a given
samplingrate $f_s$ \eqref{ssl:eq:simcont} has to be discretized.
Simply replacing $x_i(t - \lVert P - S_i\rVert/c)$ with
$x_i(n - f_s \lVert P - S_i\rVert/c)$ with
$n \in \mathbb{N}$ doesn't work because
$f_s \lVert P - S_i\rVert/c \not \in \mathbb{N}$ in most cases.
To implement this $f_s \lVert P - S_i\rVert/c$ is rounded to
its nearest integer $d_{P,S_i}$.
Now the delayed signal is $x_i(n - d_{P,S_i})$.
To achieve sub sample delays this signal is then filtered
with a Fractional Delay FIR Filter with a delay of
$f_s \lVert P - S_i\rVert/c - d_{P,S_i}$.


